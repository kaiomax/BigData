{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside Movies\n",
    "\n",
    "Analysing movies data from IMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, Javascript\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse HTML from IMDB and generate Network\n",
    "\n",
    "Use BeautifulSoup for pulling data out of IMDB titles and persons pages to generate a network visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on URL extract the IMDB id\n",
    "def get_imdb_id(href_text):\n",
    "    m = re.search('(?:[\\w]*[\\d]{7})', href_text)\n",
    "\n",
    "    if m:\n",
    "        return m.group(0)\n",
    "\n",
    "# Generate soup from URL\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize network data\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "def add_node(id_, label, group, image = None):\n",
    "    search = [node for node in nodes if node['id'] == id_]\n",
    "    \n",
    "    if(len(search) == 0):\n",
    "        node = {\n",
    "            'id': id_,\n",
    "            'label': label,\n",
    "            'group': group\n",
    "        }\n",
    "        if image is not None:\n",
    "            node['shape'] = 'circularImage'\n",
    "            node['image'] = image\n",
    "            node['size']  = 20\n",
    "        nodes.append(node)\n",
    "        return node\n",
    "    else:\n",
    "        return search[0]\n",
    "\n",
    "def add_edge(node_from, node_to, label):\n",
    "    search = [edge for edge in edges if (edge['from'] == node_from['id'] and edge['to'] == node_to['id'] and edge['label'] == label)]\n",
    "    \n",
    "    if(len(search) == 0):\n",
    "        edges.append({ 'from': node_from['id'], 'to': node_to['id'], 'label': label })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Person page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_person(imdb_id, max_depth, base_node = None, current_depth = 1):\n",
    "    if(current_depth > max_depth):\n",
    "        return\n",
    "\n",
    "    base_url = 'http://www.imdb.com/name/'\n",
    "    soup = get_soup(base_url + imdb_id)\n",
    "    \n",
    "    image = soup.find('td', id='img_primary').find('img')\n",
    "    if image is not None:\n",
    "        image = image.get('src')\n",
    "        base_node['shape'] = 'circularImage'\n",
    "        base_node['image'] = image\n",
    "        base_node['size']  = 20\n",
    "    \n",
    "    knowfor_tags = soup.select('div#knownfor div.knownfor-title')\n",
    "    movies = [{\n",
    "        'id': get_imdb_id(movie_tag.find('div', class_ = 'knownfor-title-role').find('a').get('href')),\n",
    "        'name': movie_tag.find('div', class_ = 'knownfor-title-role').find('a').text.strip(),\n",
    "        'url': movie_tag.find('div', class_ = 'knownfor-title-role').find('a').get('href'),\n",
    "        'image': movie_tag.find('img').get('src') if movie_tag.find('img') else None\n",
    "    } for movie_tag in knowfor_tags]\n",
    "\n",
    "    for movie in movies:\n",
    "        node = add_node(movie['id'], movie['name'], 'Movie', movie['image'])\n",
    "        add_edge(node, base_node, 'KF')\n",
    "        parse_title(imdb_id = movie['id'], max_depth = max_depth, base_node = node, current_depth = current_depth + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Title page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_title(imdb_id, max_depth, base_node = None, current_depth = 1):\n",
    "    if(current_depth > max_depth):\n",
    "        return\n",
    "\n",
    "    base_url = 'http://www.imdb.com/title/'\n",
    "    soup = get_soup(base_url + imdb_id)\n",
    "    \n",
    "    if(not base_node):\n",
    "        title_tags = soup.find_all('h1', itemprop='name')[0]\n",
    "        title = title_tags.text\n",
    "        year = title_tags.select('span#titleYear')[0].text\n",
    "        movie = title.replace(year, '').strip()\n",
    "        movie_image = soup.find('div', class_ = 'poster')\n",
    "        if movie_image:\n",
    "            movie_image = movie_image.find('img').get('src')\n",
    "        \n",
    "        base_node = add_node(imdb_id, movie, 'Movie', movie_image)\n",
    "        \n",
    "    def get_plot_data(soup, url_base, key):\n",
    "        item_tags = soup.find_all('span', itemprop = key, itemtype = 'http://schema.org/Person')\n",
    "        return [{\n",
    "            'id': get_imdb_id(tag.find_all('a')[0].get('href')),\n",
    "            'name': tag.find_all('span', itemprop='name')[0].text,\n",
    "            'url': url_base + tag.find_all('a')[0].get('href')\n",
    "        } for tag in item_tags]\n",
    "\n",
    "    directors = get_plot_data(soup, base_url, 'director')\n",
    "    writers = get_plot_data(soup, base_url, 'creator')\n",
    "    stars = get_plot_data(soup, base_url, 'actors')\n",
    "    genres = soup.select('.title_wrapper')[0].find_all('a', href = re.compile('/genre/'))\n",
    "    genres = [{\n",
    "        'id': genre.get('href').split('?ref')[0],\n",
    "        'name': genre.text,\n",
    "        'url': base_url + genre.get('href')\n",
    "    } for genre in genres]\n",
    "\n",
    "    for genre in genres:\n",
    "        add_edge(add_node(genre['id'], genre['name'], 'Genre'), base_node, 'G')\n",
    "\n",
    "    def add_person_items(items, label):\n",
    "        for item in items:\n",
    "            node = add_node(item['id'], item['name'], 'Person')\n",
    "            add_edge(node, base_node, label)\n",
    "\n",
    "            parse_person(\n",
    "                imdb_id = item['id'],\n",
    "                max_depth = max_depth,\n",
    "                base_node = node,\n",
    "                current_depth = current_depth + 1\n",
    "            )\n",
    "\n",
    "    add_person_items(directors, 'D')\n",
    "    add_person_items(writers, 'W')\n",
    "    add_person_items(stars, 'S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the data and populate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_network_data(imdb_url, max_depth = 3):\n",
    "    imdb_id = get_imdb_id(imdb_url)\n",
    "    \n",
    "    if imdb_id is None:\n",
    "        print('Could not extract IMDB id from the URL. Insert a valid IMDB url entry.')\n",
    "        return\n",
    "\n",
    "    if 'tt' in imdb_id:\n",
    "        parse_title(imdb_id, max_depth = max_depth)\n",
    "    elif 'nm' in imdb_id:\n",
    "        parse_person(imdb_id, max_depth = max_depth)\n",
    "    else:\n",
    "        print('This type of entry is not parseable.')\n",
    "\n",
    "    print('Data is loaded! Run the next cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Movie input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_input = widgets.Text(placeholder='Pulp Fiction...')\n",
    "index_input = widgets.Text(placeholder='1...')\n",
    "label_results = widgets.HTML(value='')\n",
    "\n",
    "box_search = widgets.VBox([\n",
    "    widgets.Label(value='Search movie:'),\n",
    "    search_input,\n",
    "    label_results\n",
    "])\n",
    "\n",
    "display(box_search)\n",
    "\n",
    "titles = []\n",
    "title = None\n",
    "movie = ''\n",
    "\n",
    "# Find IMDB titles results for the query\n",
    "def handle_search_submit(sender):\n",
    "    label_results.value = 'Loading...'\n",
    "    \n",
    "    movie = search_input.value\n",
    "    \n",
    "    query_token = '+'.join(search_input.value.split(' '))\n",
    "    search_url = 'http://www.imdb.com/find?q={}&s=all'.format(query_token)\n",
    "    page = requests.get(search_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    sections = soup.find_all('div', class_='findSection')\n",
    "\n",
    "    has_titles = lambda tag : 'Titles' in tag.find('h3', class_='findSectionHeader').text\n",
    "    section = [section for section in sections if has_titles(section)]\n",
    "\n",
    "    if len(section) > 0:\n",
    "        result_list = section[0].find('table', class_='findList').find_all('td', class_='result_text')\n",
    "\n",
    "    titles_html = ''\n",
    "\n",
    "    for item in result_list:\n",
    "        titles.append({\n",
    "            'url': item.find('a').get('href'),\n",
    "            'text': item.text\n",
    "        })\n",
    "        titles_html += '<b>{0}</b> - {1}<br/>'.format(len(titles), item.text)\n",
    "    \n",
    "    label_results.value = titles_html\n",
    "    \n",
    "    box_index = widgets.VBox([\n",
    "        widgets.Label(value=\"Type the index of the desired movie to analyze:\"),\n",
    "        index_input\n",
    "    ])\n",
    "    display(box_index)\n",
    "\n",
    "# Select the item to generate network\n",
    "def handle_index_submit(sender):  \n",
    "    index = int(index_input.value) - 1\n",
    "    title = titles[index]\n",
    "    print('Loading data for: ' + title['text'] + '\\nWait...')\n",
    "    populate_network_data(title['url'])\n",
    "\n",
    "search_input.on_submit(handle_search_submit)\n",
    "index_input.on_submit(handle_index_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Movie network visualization\n",
    "\n",
    "> See in the README how to install vis.js library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<div id=\"imdb-movie-network\">HTML element to be a container for the network</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Increase the size of the first node\n",
    "if 'size' in nodes[0]:\n",
    "    nodes[0]['size'] *= 2\n",
    "\n",
    "# Transform the graph into a JSON graph\n",
    "data = { 'nodes': nodes, 'edges': edges }\n",
    "jsonGraph = json.dumps(data, indent = 4)\n",
    "\n",
    "# Clear nodes and edges\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "# Send to Javascript\n",
    "Javascript(\"\"\"window.jsonGraph={};\"\"\".format(jsonGraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vis and generate network visualization inside the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "requirejs.config({\n",
    "    paths: {\n",
    "        vis: 'vis'\n",
    "    }\n",
    "});\n",
    "\n",
    "require(['vis'], function(vis){\n",
    "    var container = document.getElementById('imdb-movie-network');\n",
    "    var options = {\n",
    "        width: '900px',\n",
    "        height: '500px',\n",
    "        nodes: {\n",
    "            shape: 'dot',\n",
    "            size: 10,\n",
    "            borderWidth: 2\n",
    "        },\n",
    "        edges: {\n",
    "            font: {\n",
    "                size: 12\n",
    "            }\n",
    "        }\n",
    "    };\n",
    "    \n",
    "    // Load the JSON graph we generated from IPython input\n",
    "    var graph = window.jsonGraph;\n",
    "    \n",
    "    // Display Graph\n",
    "    var network = new vis.Network(container, graph, options);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> View the network inside the HTML container. (4 cells above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "\n",
    "- [https://www.codementor.io/isaib.cicourel/visjs-visualization-in-jupyter-notebook-phgb3fjv0][1]\n",
    "- [https://ipywidgets.readthedocs.io/en/latest/][2]\n",
    "- [http://visjs.org/docs/network/][3]\n",
    "\n",
    "[1]: https://www.codementor.io/isaib.cicourel/visjs-visualization-in-jupyter-notebook-phgb3fjv0\n",
    "[2]: https://ipywidgets.readthedocs.io/en/latest/\n",
    "[3]: http://visjs.org/docs/network/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "1a81aacd500449abafd7d0b72308d924": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "ac60ee548cc34956888ea06341b50d98": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ac7ae2407fa64fd4a0d9dd393e47bed0": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
